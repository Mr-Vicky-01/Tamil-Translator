{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U accelerate==0.27.1\n!pip install -q -U transformers==4.38.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U datasets==2.16.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport transformers\nimport tensorflow as tf\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\nfrom transformers import AdamWeightDecay","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:50:06.219642Z","iopub.execute_input":"2024-03-23T09:50:06.219926Z","iopub.status.idle":"2024-03-23T09:50:06.224779Z","shell.execute_reply.started":"2024-03-23T09:50:06.219900Z","shell.execute_reply":"2024-03-23T09:50:06.223822Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"Mr-Vicky-01/English-Tamil-Translator\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:50:06.225729Z","iopub.execute_input":"2024-03-23T09:50:06.225965Z","iopub.status.idle":"2024-03-23T09:50:10.158384Z","shell.execute_reply.started":"2024-03-23T09:50:06.225944Z","shell.execute_reply":"2024-03-23T09:50:10.157511Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def language_translator(text):\n    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n    # model = AutoModelForSeq2SeqLM.from_pretrained(\"finetune-EN-to-Ta/\")\n    tokenized = tokenizer([text], return_tensors='pt')\n    out = model.generate(**tokenized, max_length=128)\n    return tokenizer.decode(out[0],skip_special_tokens=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_to_translate = \"i have to play football now!\"\noutput = language_translator(text_to_translate)\nprint(output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_datasets = load_dataset(\"Hemanth-thunder/en_ta\")","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:50:41.082414Z","iopub.execute_input":"2024-03-23T09:50:41.082787Z","iopub.status.idle":"2024-03-23T09:50:42.426162Z","shell.execute_reply.started":"2024-03-23T09:50:41.082760Z","shell.execute_reply":"2024-03-23T09:50:42.425148Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:50:47.586678Z","iopub.execute_input":"2024-03-23T09:50:47.587050Z","iopub.status.idle":"2024-03-23T09:50:47.594271Z","shell.execute_reply.started":"2024-03-23T09:50:47.587022Z","shell.execute_reply":"2024-03-23T09:50:47.593318Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'en', 'ta'],\n        num_rows: 285630\n    })\n    validation: Dataset({\n        features: ['Unnamed: 0', 'en', 'ta'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['Unnamed: 0', 'en', 'ta'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:50:50.171358Z","iopub.execute_input":"2024-03-23T09:50:50.172299Z","iopub.status.idle":"2024-03-23T09:50:50.178164Z","shell.execute_reply.started":"2024-03-23T09:50:50.172263Z","shell.execute_reply":"2024-03-23T09:50:50.177458Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'Unnamed: 0': 0,\n 'en': \"MMA vice president Qazi Hussain Ahmad declared last month: 'We are not extremists.\\n\",\n 'ta': 'MMA கட்சியின் துணைத்தலைவர் க்வாஸி ஹுசேன் அகமத் சென்ற மாதம் பின்வருமாறு அறிவித்தார்: ``நாங்கள் தீவிரவாதிகள் அல்ல.\\n'}"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 128\nmax_target_length = 128\n\nsource_lang = \"en\"\ntarget_lang = \"ta\"\n\n\ndef preprocess_function(examples):\n    inputs = [ex for ex in examples[source_lang]]\n    targets = [ex for ex in examples[target_lang]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n\n    # Setup the tokenizer for targets\n    # with tokenizer.as_target_tokenizer():\n    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:50:51.106429Z","iopub.execute_input":"2024-03-23T09:50:51.107141Z","iopub.status.idle":"2024-03-23T09:50:51.113369Z","shell.execute_reply.started":"2024-03-23T09:50:51.107109Z","shell.execute_reply":"2024-03-23T09:50:51.112473Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"preprocess_function(raw_datasets[\"train\"][:1])","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:50:52.721152Z","iopub.execute_input":"2024-03-23T09:50:52.721564Z","iopub.status.idle":"2024-03-23T09:50:52.729545Z","shell.execute_reply.started":"2024-03-23T09:50:52.721535Z","shell.execute_reply":"2024-03-23T09:50:52.728648Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[128022, 100, 8087, 45944, 20120, 1315, 2956, 176, 9652, 40, 37513, 30298, 241, 11469, 119530, 9, 244, 41895, 4234, 4632, 25335, 33544, 5, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[128022, 100, 8087, 3000, 23198, 45900, 19363, 40323, 2895, 7128, 13378, 3000, 12037, 9110, 21477, 4685, 23618, 6133, 4378, 12882, 82091, 3068, 6285, 89996, 10093, 28215, 32018, 73075, 9704, 9429, 61507, 103297, 9, 22, 56797, 24332, 7960, 25706, 94292, 9110, 5174, 6699, 112439, 5, 2]]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_test = raw_datasets.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:50:53.896050Z","iopub.execute_input":"2024-03-23T09:50:53.896935Z","iopub.status.idle":"2024-03-23T09:54:26.521850Z","shell.execute_reply.started":"2024-03-23T09:50:53.896900Z","shell.execute_reply":"2024-03-23T09:54:26.520905Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/285630 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deda51ff340842999605031128da1a7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7629994f23e54dbf8f2d94b6602e4e99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c78db71eed6a45b1ab84feda28cc9430"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_test","metadata":{"execution":{"iopub.status.busy":"2024-03-23T09:54:26.523705Z","iopub.execute_input":"2024-03-23T09:54:26.524414Z","iopub.status.idle":"2024-03-23T09:54:26.530137Z","shell.execute_reply.started":"2024-03-23T09:54:26.524377Z","shell.execute_reply":"2024-03-23T09:54:26.529224Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'en', 'ta', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 285630\n    })\n    validation: Dataset({\n        features: ['Unnamed: 0', 'en', 'ta', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['Unnamed: 0', 'en', 'ta', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel_args = Seq2SeqTrainingArguments(\n    output_dir=\"finetuned-EN-to-Ta\",  \n    overwrite_output_dir=True,  \n    do_train=True,  \n    logging_dir=\"logs\",  \n    logging_steps=100,  # Increase logging frequency for more insights\n    save_steps=5000000,  # Save model checkpoints more frequently\n    save_total_limit=1,  # Keep more checkpoints\n    num_train_epochs=1,  # Extend training to allow for more optimization\n    per_device_train_batch_size=8,  # Increase batch size for more efficient training\n    gradient_accumulation_steps=4,  # Increase gradient accumulation for stable training\n    learning_rate=4e-5,  # Slightly lower learning rate to fine-tune more gently\n    warmup_steps=2500,  # Increase warmup steps for better adaptation\n    weight_decay=0.01,  \n    adam_beta1=0.9,  \n    adam_beta2=0.98,  \n    adam_epsilon=1e-8,  \n    lr_scheduler_type=\"linear\",  \n    predict_with_generate=True,  \n    fp16=True,  \n    seed=42,  \n    report_to=\"wandb\",  \n    run_name=\"finetuned-EN-to-Ta\",  \n)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T10:45:37.402872Z","iopub.execute_input":"2024-03-23T10:45:37.403676Z","iopub.status.idle":"2024-03-23T10:45:37.413262Z","shell.execute_reply.started":"2024-03-23T10:45:37.403640Z","shell.execute_reply":"2024-03-23T10:45:37.411981Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T10:45:37.777724Z","iopub.execute_input":"2024-03-23T10:45:37.778098Z","iopub.status.idle":"2024-03-23T10:45:37.784680Z","shell.execute_reply.started":"2024-03-23T10:45:37.778069Z","shell.execute_reply":"2024-03-23T10:45:37.783468Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    model_args,\n    train_dataset=tokenized_test[\"train\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T10:45:42.602488Z","iopub.execute_input":"2024-03-23T10:45:42.603561Z","iopub.status.idle":"2024-03-23T10:45:42.628421Z","shell.execute_reply.started":"2024-03-23T10:45:42.603519Z","shell.execute_reply":"2024-03-23T10:45:42.627378Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T10:45:43.092304Z","iopub.execute_input":"2024-03-23T10:45:43.092682Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='858' max='8926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 858/8926 23:32 < 3:41:54, 0.61 it/s, Epoch 0.10/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.408800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.180200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.101400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.033100</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.952100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.891800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.818400</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.748600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.model.save_pretrained('finetune-English-to-Tamil')","metadata":{"execution":{"iopub.status.busy":"2024-03-23T10:42:28.397211Z","iopub.execute_input":"2024-03-23T10:42:28.397601Z","iopub.status.idle":"2024-03-23T10:42:30.711386Z","shell.execute_reply.started":"2024-03-23T10:42:28.397572Z","shell.execute_reply":"2024-03-23T10:42:30.710243Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}\n","output_type":"stream"}]},{"cell_type":"code","source":"model1 = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/finetune-English-to-Tamil\")","metadata":{"execution":{"iopub.status.busy":"2024-03-23T10:43:12.047590Z","iopub.execute_input":"2024-03-23T10:43:12.047989Z","iopub.status.idle":"2024-03-23T10:43:15.071003Z","shell.execute_reply.started":"2024-03-23T10:43:12.047957Z","shell.execute_reply":"2024-03-23T10:43:15.069744Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def language_translator(text):\n    # model = AutoModelForSeq2SeqLM.from_pretrained(\"finetune-EN-to-Ta/\")\n    tokenized = tokenizer([text], return_tensors='pt')\n    out = model1.generate(**tokenized, max_length=128)\n    return tokenizer.decode(out[0],skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T10:43:18.862442Z","iopub.execute_input":"2024-03-23T10:43:18.863154Z","iopub.status.idle":"2024-03-23T10:43:18.869369Z","shell.execute_reply.started":"2024-03-23T10:43:18.863125Z","shell.execute_reply":"2024-03-23T10:43:18.868150Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# text_to_translate = raw_datasets[\"test\"][\"en\"][5]\noutput = language_translator(\"ran out of memory\")\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T10:45:22.657498Z","iopub.execute_input":"2024-03-23T10:45:22.658396Z","iopub.status.idle":"2024-03-23T10:45:24.916278Z","shell.execute_reply.started":"2024-03-23T10:45:22.658355Z","shell.execute_reply":"2024-03-23T10:45:24.915234Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"நினைவில்லாமல் ஓடினார்கள்!\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_datasets[\"test\"][5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}